import requests
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
from db import insert_malicious_url
from logger import logger  # logger íŒŒì¼ì—ì„œ ê°€ì ¸ì˜¤ê¸°
import os

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
                "(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}

os.makedirs('./log', exist_ok=True)

class Collector:
    def __init__(self) -> None:
        self.data_dic = dict()

    def nola_collection(self):
        """Noladefenseì—ì„œ í”¼ì‹± URL ìˆ˜ì§‘"""

        def nola_preprocess(ent):
            """í…ìŠ¤íŠ¸ ë³€í™˜: 'hxxp' -> 'http', '[.]' -> '.'"""
            text = ent.text.strip()
            return text.replace('hxxp', 'http').replace('[.]', '.')

        yesterday = datetime.now() - timedelta(days=1)
        ym = yesterday.strftime('%Y/%m')  # ì—°/ì›” (YYYY/MM)
        date = yesterday.strftime('%Y-%m-%d')  # ì—°-ì›”-ì¼ (YYYY-MM-DD)

        nola_url = f"https://www.noladefense.net/{ym}/{date}-daily-phishing-url-summary.html"

        try:
            response = requests.get(nola_url, headers=HEADERS)
            response.raise_for_status()  # HTTP ì˜¤ë¥˜ ë°œìƒ ì‹œ ì˜ˆì™¸ ë°œìƒ

            soup = BeautifulSoup(response.text, 'html.parser')
            phishing_urls = [
                nola_preprocess(etr)
                for etr in soup.find_all('li')
                if etr.text.strip().startswith('hxxp')
            ]

            self.data_dic['Noladefense'] = phishing_urls
            logger.info(f"âœ… Noladefenseì—ì„œ {len(phishing_urls)}ê°œì˜ URL ìˆ˜ì§‘ ì™„ë£Œ")

        except requests.exceptions.RequestException as e:
            logger.error(f"âš ï¸ Noladefense ìš”ì²­ ì‹¤íŒ¨: {e}")

    def openphish_collection(self):
        """OpenPhishì—ì„œ í”¼ì‹± URL ìˆ˜ì§‘"""
        openphish_url = 'https://raw.githubusercontent.com/openphish/public_feed/refs/heads/main/feed.txt'

        try:
            response = requests.get(openphish_url, headers=HEADERS)
            response.raise_for_status()  # HTTP ì˜¤ë¥˜ ë°œìƒ ì‹œ ì˜ˆì™¸ ë°œìƒ

            phishing_urls = [url.strip() for url in response.text.split('\n') if url.strip()]
            self.data_dic['OpenPhish'] = phishing_urls
            logger.info(f"âœ… OpenPhishì—ì„œ {len(phishing_urls)}ê°œì˜ URL ìˆ˜ì§‘ ì™„ë£Œ")

        except requests.exceptions.RequestException as e:
            logger.error(f"âš ï¸ OpenPhish ìš”ì²­ ì‹¤íŒ¨: {e}")

    def run(self):
        """ëª¨ë“  ìˆ˜ì§‘ ë©”ì„œë“œ ì‹¤í–‰ í›„ ê²°ê³¼ ì¶œë ¥"""
        logger.info("ğŸš€ Mal URL ìˆ˜ì§‘ ì‘ì—… ì‹œì‘")
        try:
            self.nola_collection()
            self.openphish_collection()
            logger.info("ğŸš€ Mal URL DB Insert Start")
            for source, url_list in self.data_dic.items():
                cnt = 0
                for url in url_list:
                    status = insert_malicious_url(url, source)
                    if status:
                        cnt += 1
                
                logger.info(f"ğŸ“Œ ì €ì¥ ì™„ë£Œ: {cnt:,} (ì¶œì²˜: {source})")

            logger.info("âœ… ëª¨ë“  ìˆ˜ì§‘ ë° ì €ì¥ ì‘ì—… ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        finally:
            logger.info("ğŸ›‘ Mal URL ìˆ˜ì§‘ ì‘ì—… ì¢…ë£Œ")


# ì‹¤í–‰ ì‹œ ë¡œê¹…
if __name__ == '__main__':
    logger.info("ğŸ”„ ìˆ˜ì§‘ê¸° ì‹¤í–‰ ì‹œì‘")
    collector = Collector()
    collector.run()
    logger.info("ğŸ ìˆ˜ì§‘ê¸° ì‹¤í–‰ ì¢…ë£Œ")
